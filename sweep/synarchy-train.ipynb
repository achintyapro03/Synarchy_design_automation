{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13494200,"sourceType":"datasetVersion","datasetId":8567589}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:05:39.825972Z","iopub.execute_input":"2025-10-27T19:05:39.826425Z","iopub.status.idle":"2025-10-27T19:05:41.461386Z","shell.execute_reply.started":"2025-10-27T19:05:39.826398Z","shell.execute_reply":"2025-10-27T19:05:41.460666Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport os\nimport warnings\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\ntf.get_logger().setLevel('ERROR')\nwarnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\nDATA_FILENAME = '/kaggle/input/gem5-results/gem5_results.csv'  # <--- !! RENAME THIS TO YOUR CSV FILE !!\n\nINPUT_FEATURES = [\n    'cpu_clock_GHz', 'l1i_kb', 'l1d_kb', 'l1_assoc', 'l2_kb',\n    'l2_assoc', 'fetchWidth', 'decodeWidth', 'issueWidth', 'commitWidth',\n    'numROBEntries', 'numIQEntries', 'LQEntries', 'SQEntries', 'branch_predictor'\n]\n\nOUTPUT_METRICS = [\n    'Area', 'Peak Power', 'Total Leakage', 'Peak Dynamic', \n    'Subthreshold Leakage', 'Gate Leakage', 'Runtime Dynamic', 'ipc',\n    'branch_misprediction_rate', 'icache_miss_rate', \n    'dcache_read_miss_rate', 'dcache_write_miss_rate'\n]\n\nCATEGORICAL_FEATURES = ['branch_predictor']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:05:41.462074Z","iopub.execute_input":"2025-10-27T19:05:41.462375Z","iopub.status.idle":"2025-10-27T19:05:54.609633Z","shell.execute_reply.started":"2025-10-27T19:05:41.462357Z","shell.execute_reply":"2025-10-27T19:05:54.608819Z"}},"outputs":[{"name":"stderr","text":"2025-10-27 19:05:42.880513: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761591943.067110      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761591943.139499      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# PART 1: DATA LOADING AND PREPROCESSING\n# ============================================================================\nprint(\"--- [Part 1] Loading and Preprocessing Data ---\")\n\nif not os.path.exists(DATA_FILENAME):\n    print(f\"Error: Could not find data file '{DATA_FILENAME}'.\")\n    print(\"Please make sure the file is in the same directory and the name is correct.\")\n    exit()\n\ntry:\n    df = pd.read_csv(DATA_FILENAME)\nexcept Exception as e:\n    print(f\"Error reading CSV file: {e}\")\n    exit()\n\ntry:\n    X_df = df[INPUT_FEATURES]\n    y_df = df[OUTPUT_METRICS]\nexcept KeyError as e:\n    print(f\"\\nError: A column name in your lists is not in the CSV file.\")\n    print(f\"Column not found: {e}\")\n    print(\"Please check your 'INPUT_FEATURES' and 'OUTPUT_METRICS' lists.\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:05:54.611366Z","iopub.execute_input":"2025-10-27T19:05:54.611844Z","iopub.status.idle":"2025-10-27T19:05:54.738594Z","shell.execute_reply.started":"2025-10-27T19:05:54.611824Z","shell.execute_reply":"2025-10-27T19:05:54.737824Z"}},"outputs":[{"name":"stdout","text":"--- [Part 1] Loading and Preprocessing Data ---\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"X_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:05:54.739419Z","iopub.execute_input":"2025-10-27T19:05:54.739681Z","iopub.status.idle":"2025-10-27T19:05:54.759949Z","shell.execute_reply.started":"2025-10-27T19:05:54.739648Z","shell.execute_reply":"2025-10-27T19:05:54.759081Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   cpu_clock_GHz  l1i_kb  l1d_kb  l1_assoc  l2_kb  l2_assoc  fetchWidth  \\\n0            3.4      16      32         1    128        16           2   \n1            1.4     128      64         2    512         4           8   \n2            3.2      64      16         8    512         4           8   \n3            2.8      64      16         1   2048         8          12   \n4            4.0     128      16         2   1024         2          12   \n\n   decodeWidth  issueWidth  commitWidth  numROBEntries  numIQEntries  \\\n0            8           2            4             32            32   \n1            2          12            8            256           128   \n2            2           2            2            128            96   \n3            4           2            4            128            96   \n4            8           8           12            192            96   \n\n   LQEntries  SQEntries                branch_predictor  \n0         64          8                            TAGE  \n1         32         32                         LocalBP  \n2         32         32                    TournamentBP  \n3         64         16  MultiperspectivePerceptron64KB  \n4         64         64  MultiperspectivePerceptron64KB  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cpu_clock_GHz</th>\n      <th>l1i_kb</th>\n      <th>l1d_kb</th>\n      <th>l1_assoc</th>\n      <th>l2_kb</th>\n      <th>l2_assoc</th>\n      <th>fetchWidth</th>\n      <th>decodeWidth</th>\n      <th>issueWidth</th>\n      <th>commitWidth</th>\n      <th>numROBEntries</th>\n      <th>numIQEntries</th>\n      <th>LQEntries</th>\n      <th>SQEntries</th>\n      <th>branch_predictor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.4</td>\n      <td>16</td>\n      <td>32</td>\n      <td>1</td>\n      <td>128</td>\n      <td>16</td>\n      <td>2</td>\n      <td>8</td>\n      <td>2</td>\n      <td>4</td>\n      <td>32</td>\n      <td>32</td>\n      <td>64</td>\n      <td>8</td>\n      <td>TAGE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.4</td>\n      <td>128</td>\n      <td>64</td>\n      <td>2</td>\n      <td>512</td>\n      <td>4</td>\n      <td>8</td>\n      <td>2</td>\n      <td>12</td>\n      <td>8</td>\n      <td>256</td>\n      <td>128</td>\n      <td>32</td>\n      <td>32</td>\n      <td>LocalBP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.2</td>\n      <td>64</td>\n      <td>16</td>\n      <td>8</td>\n      <td>512</td>\n      <td>4</td>\n      <td>8</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>128</td>\n      <td>96</td>\n      <td>32</td>\n      <td>32</td>\n      <td>TournamentBP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.8</td>\n      <td>64</td>\n      <td>16</td>\n      <td>1</td>\n      <td>2048</td>\n      <td>8</td>\n      <td>12</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n      <td>128</td>\n      <td>96</td>\n      <td>64</td>\n      <td>16</td>\n      <td>MultiperspectivePerceptron64KB</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>128</td>\n      <td>16</td>\n      <td>2</td>\n      <td>1024</td>\n      <td>2</td>\n      <td>12</td>\n      <td>8</td>\n      <td>8</td>\n      <td>12</td>\n      <td>192</td>\n      <td>96</td>\n      <td>64</td>\n      <td>64</td>\n      <td>MultiperspectivePerceptron64KB</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"y_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:05:54.760702Z","iopub.execute_input":"2025-10-27T19:05:54.760972Z","iopub.status.idle":"2025-10-27T19:05:54.776593Z","shell.execute_reply.started":"2025-10-27T19:05:54.760949Z","shell.execute_reply":"2025-10-27T19:05:54.775885Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       Area  Peak Power  Total Leakage  Peak Dynamic  Subthreshold Leakage  \\\n0  104.1838     84.1828        16.2890       63.8925               15.3246   \n1  114.8473     76.3575        18.2882       54.4357               16.9324   \n2   79.3346     65.2464        16.7377       41.6266               15.6093   \n3  110.7148     66.0129        18.2379       41.8925               17.2060   \n4  140.6207    155.9880        18.3157      132.4366               17.3131   \n\n   Gate Leakage  Runtime Dynamic     ipc  branch_misprediction_rate  \\\n0        1.1498           8.0597  0.6265                     0.0563   \n1        1.3149          10.3666  0.8389                     0.0812   \n2        1.1444           7.6594  0.7168                     0.0675   \n3        1.1710           7.5061  0.6753                     0.1243   \n4        1.2794          24.2688  0.7964                     0.1292   \n\n   icache_miss_rate  dcache_read_miss_rate  dcache_write_miss_rate  \n0            0.0112                 0.0185                  0.0104  \n1            0.0086                 0.0173                  0.0102  \n2            0.0090                 0.1015                  0.0106  \n3            0.0066                 0.0931                  0.0106  \n4            0.0075                 0.1036                  0.0106  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Area</th>\n      <th>Peak Power</th>\n      <th>Total Leakage</th>\n      <th>Peak Dynamic</th>\n      <th>Subthreshold Leakage</th>\n      <th>Gate Leakage</th>\n      <th>Runtime Dynamic</th>\n      <th>ipc</th>\n      <th>branch_misprediction_rate</th>\n      <th>icache_miss_rate</th>\n      <th>dcache_read_miss_rate</th>\n      <th>dcache_write_miss_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>104.1838</td>\n      <td>84.1828</td>\n      <td>16.2890</td>\n      <td>63.8925</td>\n      <td>15.3246</td>\n      <td>1.1498</td>\n      <td>8.0597</td>\n      <td>0.6265</td>\n      <td>0.0563</td>\n      <td>0.0112</td>\n      <td>0.0185</td>\n      <td>0.0104</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>114.8473</td>\n      <td>76.3575</td>\n      <td>18.2882</td>\n      <td>54.4357</td>\n      <td>16.9324</td>\n      <td>1.3149</td>\n      <td>10.3666</td>\n      <td>0.8389</td>\n      <td>0.0812</td>\n      <td>0.0086</td>\n      <td>0.0173</td>\n      <td>0.0102</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>79.3346</td>\n      <td>65.2464</td>\n      <td>16.7377</td>\n      <td>41.6266</td>\n      <td>15.6093</td>\n      <td>1.1444</td>\n      <td>7.6594</td>\n      <td>0.7168</td>\n      <td>0.0675</td>\n      <td>0.0090</td>\n      <td>0.1015</td>\n      <td>0.0106</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110.7148</td>\n      <td>66.0129</td>\n      <td>18.2379</td>\n      <td>41.8925</td>\n      <td>17.2060</td>\n      <td>1.1710</td>\n      <td>7.5061</td>\n      <td>0.6753</td>\n      <td>0.1243</td>\n      <td>0.0066</td>\n      <td>0.0931</td>\n      <td>0.0106</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>140.6207</td>\n      <td>155.9880</td>\n      <td>18.3157</td>\n      <td>132.4366</td>\n      <td>17.3131</td>\n      <td>1.2794</td>\n      <td>24.2688</td>\n      <td>0.7964</td>\n      <td>0.1292</td>\n      <td>0.0075</td>\n      <td>0.1036</td>\n      <td>0.0106</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"print(\"\\n--- [Part 2] Model Training and Testing ---\")\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nimport numpy as np\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_df, y_df, test_size=0.1, random_state=42\n)\nprint(f\"Training with {len(X_train)} samples, testing with {len(X_test)} samples.\")\n\nnumerical_features = [col for col in INPUT_FEATURES if col not in CATEGORICAL_FEATURES]\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numerical_features),                      # Scale numeric\n        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), CATEGORICAL_FEATURES)  # One-hot encode categorical\n    ],\n    remainder='passthrough'\n)\n\nX_train_processed = preprocessor.fit_transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\n\nn_features = X_train_processed.shape[1]\n\ny_scaler = StandardScaler()\ny_train_scaled = y_scaler.fit_transform(y_train)\ny_test_scaled = y_scaler.transform(y_test)\n\nn_outputs = y_train_scaled.shape[1]\n\nprint(f\"Original input features: {len(INPUT_FEATURES)}\")\nprint(f\"Processed & scaled input features: {n_features}\")\nprint(f\"Output metrics: {n_outputs}\")\n\nsurrogate_model = Sequential([\n    Dense(64, kernel_regularizer=l2(1e-4), input_shape=(n_features,)),\n    LeakyReLU(alpha=0.1),\n    BatchNormalization(),\n    Dropout(0.1),\n\n    Dense(32, kernel_regularizer=l2(1e-4)),\n    LeakyReLU(alpha=0.1),\n    BatchNormalization(),\n    Dropout(0.1),\n\n    Dense(16, kernel_regularizer=l2(1e-4)),\n    LeakyReLU(alpha=0.1),\n\n    Dense(n_outputs, activation='linear')  # Output layer for regression\n])\n\nsurrogate_model.compile(\n    optimizer='adam',\n    loss='mean_squared_error',\n    metrics=['mean_absolute_percentage_error']\n)\n\nearly_stop = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    restore_best_weights=True,\n    verbose=1\n)\n\nlr_reduce = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=5,\n    verbose=1\n)\n\nhistory = surrogate_model.fit(\n    X_train_processed, y_train_scaled,\n    validation_split=0.2,\n    epochs=500,\n    batch_size=16,\n    callbacks=[early_stop, lr_reduce],\n    verbose=0\n)\n\nprint(\"Model training complete. ✅\")\n\ny_pred_scaled = surrogate_model.predict(X_test_processed)\ny_pred = y_scaler.inverse_transform(y_pred_scaled)\n\nmape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\nprint(f\"Test MAPE (all outputs avg): {mape:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:05:54.777373Z","iopub.execute_input":"2025-10-27T19:05:54.777692Z","iopub.status.idle":"2025-10-27T19:06:59.415148Z","shell.execute_reply.started":"2025-10-27T19:05:54.777670Z","shell.execute_reply":"2025-10-27T19:06:59.414505Z"}},"outputs":[{"name":"stdout","text":"\n--- [Part 2] Model Training and Testing ---\nTraining with 2250 samples, testing with 250 samples.\nOriginal input features: 15\nProcessed & scaled input features: 20\nOutput metrics: 12\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\nI0000 00:00:1761591955.531290      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1761591959.886553      98 service.cc:148] XLA service 0x79fe84014010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1761591959.887013      98 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1761591960.236306      98 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1761591962.219584      98 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 88: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 103: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 115: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 127: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 139: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 144: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\nEpoch 144: early stopping\nRestoring model weights from the end of the best epoch: 134.\nModel training complete. ✅\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\nTest MAPE (all outputs avg): 3.91%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nprint(\"\\n--- Evaluating Model on Test Set ---\")\n\nloss, mape = surrogate_model.evaluate(X_test_processed, y_test_scaled, verbose=0)\nprint(f\"Test Set Loss (MSE, scaled): {loss:.4f}\")\nprint(f\"Test Set Mean Absolute Percentage Error (MAPE, scaled): {mape:.2f}%\")\n\ny_pred_scaled = surrogate_model.predict(X_test_processed, verbose=0)\ny_pred_test = y_scaler.inverse_transform(y_pred_scaled)\n\nr2 = r2_score(y_test, y_pred_test)\nprint(f\"Test Set R-squared (R², original scale): {r2:.4f} (Closer to 1.0 is better)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:06:59.415977Z","iopub.execute_input":"2025-10-27T19:06:59.416726Z","iopub.status.idle":"2025-10-27T19:07:00.077799Z","shell.execute_reply.started":"2025-10-27T19:06:59.416699Z","shell.execute_reply":"2025-10-27T19:07:00.077108Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating Model on Test Set ---\nTest Set Loss (MSE, scaled): 0.0424\nTest Set Mean Absolute Percentage Error (MAPE, scaled): 45.75%\nTest Set R-squared (R², original scale): 0.9635 (Closer to 1.0 is better)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(\"\\n--- ML-Powered Random Search (Find New Configs) ---\")\n\nDISCRETE_PARAMS = {\n    \"l1i_kb\": [16, 32, 64, 128],\n    \"l1d_kb\": [16, 32, 64, 128],\n    \"l1_assoc\": [1, 2, 4, 8],\n    \"l2_kb\": [128, 256, 512, 1024, 2048],\n    \"l2_assoc\": [2, 4, 8, 16],\n    # Add other integer parameters here if needed\n    # \"num_cores\": [1, 2, 4, 8, 16],\n}\n\nsearch_space = {}\n\nfor col in numerical_features:\n    if col in DISCRETE_PARAMS:\n        # Special discrete parameter\n        search_space[col] = ('discrete', DISCRETE_PARAMS[col])\n    else:\n        # Continuous int or float parameter\n        is_int = pd.api.types.is_integer_dtype(X_df[col])\n        search_space[col] = ('int' if is_int else 'float', X_df[col].min(), X_df[col].max())\n\nfor col in CATEGORICAL_FEATURES:\n    search_space[col] = ('categorical', X_df[col].unique())\n\nprint(\"\\n--- Generated Search Space ---\")\nfor param, (dtype, *bounds) in search_space.items():\n    if dtype == 'discrete':\n        print(f\" - {param} (discrete): {bounds[0]}\")\n    elif dtype == 'categorical':\n        print(f\" - {param} (categorical): {bounds[0]}\")\n    else:\n        print(f\" - {param} ({dtype}): min={bounds[0]}, max={bounds[1]}\")\nprint(\"---------------------------------\")\n\ndef generate_random_configs(n, space):\n    \"\"\"Generates n random configurations as a DataFrame.\"\"\"\n    configs = {}\n    for col, (dtype, *bounds) in space.items():\n        if dtype == 'int':\n            configs[col] = np.random.randint(bounds[0], bounds[1] + 1, size=n)\n        elif dtype == 'float':\n            configs[col] = np.random.uniform(bounds[0], bounds[1], size=n)\n        elif dtype == 'discrete':\n            configs[col] = np.random.choice(bounds[0], size=n)\n        elif dtype == 'categorical':\n            configs[col] = np.random.choice(bounds[0], size=n)\n    return pd.DataFrame(configs)\n\n\ndef find_topk_from_model(model, preproc, space, output_constraints, input_constraints=None, \n                         objective=('pca','min'), n_iter=100000, top_k=5):\n\n    print(f\"Running ML-powered random search for {n_iter} iterations...\")\n\n    random_X_df = generate_random_configs(n_iter, space)\n\n    if input_constraints:\n        feasible_mask = pd.Series(True, index=random_X_df.index)\n        for key, cond_list in input_constraints.items():\n            if not isinstance(cond_list, list):\n                cond_list = [cond_list]\n            for op, val in cond_list:\n                if op == '<=':\n                    feasible_mask &= (random_X_df[key] <= val)\n                elif op == '>=':\n                    feasible_mask &= (random_X_df[key] >= val)\n                elif op == '<':\n                    feasible_mask &= (random_X_df[key] < val)\n                elif op == '>':\n                    feasible_mask &= (random_X_df[key] > val)\n                elif op == '==':\n                    feasible_mask &= np.isclose(random_X_df[key], val)\n                else:\n                    raise ValueError(f\"Unsupported operator {op}\")\n        random_X_df = random_X_df.loc[feasible_mask]\n        if random_X_df.empty:\n            print(\"No configurations satisfy input constraints!\")\n            return None, None\n\n    random_X_processed = preproc.transform(random_X_df)\n    y_pred_scaled = model.predict(random_X_processed, batch_size=1024, verbose=0)\n    y_pred_unscaled = y_scaler.inverse_transform(y_pred_scaled)\n    y_pred_df = pd.DataFrame(y_pred_unscaled, columns=OUTPUT_METRICS, index=random_X_df.index)\n\n    y_pred_df['pca'] = y_pred_df['Peak Dynamic'] * y_pred_df['Area'] / y_pred_df['ipc']\n    y_pred_df['cpi'] = 1.0 / y_pred_df['ipc'].replace(0, np.nan)\n\n    feasible_mask = pd.Series(True, index=y_pred_df.index)\n    for key, cond_list in output_constraints.items():\n        if key not in y_pred_df.columns:\n            print(f\"Warning: {key} not in predicted outputs.\")\n            feasible_mask &= False\n            continue\n        if not isinstance(cond_list, list):\n            cond_list = [cond_list]\n        for op, val in cond_list:\n            if op == '<=':\n                feasible_mask &= (y_pred_df[key] <= val)\n            elif op == '>=':\n                feasible_mask &= (y_pred_df[key] >= val)\n            elif op == '<':\n                feasible_mask &= (y_pred_df[key] < val)\n            elif op == '>':\n                feasible_mask &= (y_pred_df[key] > val)\n            elif op == '==':\n                feasible_mask &= np.isclose(y_pred_df[key], val)\n            else:\n                raise ValueError(f\"Unsupported operator {op}\")\n\n    feasible_X = random_X_df.loc[feasible_mask]\n    feasible_y = y_pred_df.loc[feasible_mask]\n\n    print(f\"Found {len(feasible_y)} *predicted* feasible configurations.\")\n    if feasible_y.empty:\n        return None, None\n\n    obj_col, obj_mode = objective\n    ascending = True if obj_mode == 'min' else False\n    top_indices = feasible_y.sort_values(by=obj_col, ascending=ascending).head(top_k).index\n\n    print(feasible_X.shape, feasible_y.shape)\n\n    return feasible_X.loc[top_indices], feasible_y.loc[top_indices]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:07:00.078675Z","iopub.execute_input":"2025-10-27T19:07:00.078994Z","iopub.status.idle":"2025-10-27T19:07:00.101888Z","shell.execute_reply.started":"2025-10-27T19:07:00.078973Z","shell.execute_reply":"2025-10-27T19:07:00.101168Z"}},"outputs":[{"name":"stdout","text":"\n--- ML-Powered Random Search (Find New Configs) ---\n\n--- Generated Search Space ---\n - cpu_clock_GHz (float): min=1.0, max=4.0\n - l1i_kb (discrete): [16, 32, 64, 128]\n - l1d_kb (discrete): [16, 32, 64, 128]\n - l1_assoc (discrete): [1, 2, 4, 8]\n - l2_kb (discrete): [128, 256, 512, 1024, 2048]\n - l2_assoc (discrete): [2, 4, 8, 16]\n - fetchWidth (int): min=2, max=12\n - decodeWidth (int): min=2, max=12\n - issueWidth (int): min=2, max=12\n - commitWidth (int): min=2, max=12\n - numROBEntries (int): min=32, max=256\n - numIQEntries (int): min=16, max=128\n - LQEntries (int): min=8, max=64\n - SQEntries (int): min=8, max=64\n - branch_predictor (categorical): ['TAGE' 'LocalBP' 'TournamentBP' 'MultiperspectivePerceptron64KB'\n 'BiModeBP' 'TAGE_SC_L_64KB']\n---------------------------------\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\" [Part 3] Inference / Optimization (Top-K Designs)\")\nprint(\"=\"*50)\n\nOUTPUT_CONSTRAINTS = {\n    'Area': [('<=', 150)],\n    'Peak Power': [('<=', 120)],\n    'ipc': [('>=', 1.0)],\n    'branch_misprediction_rate': [('<=', 0.06), ('>=', 0.0)],\n    'dcache_write_miss_rate': [('>=', 0.0)],\n    'dcache_read_miss_rate': [('>=', 0.0)],\n    'icache_miss_rate': [('>=', 0.0)]\n}\n\nINPUT_CONSTRAINTS = {\n    'cpu_clock_GHz': [('>=', 0.8), ('<=', 1.5)]\n}\n\nOBJECTIVE = ('pca', 'min')\n\n# top_k = int(input(\"Enter number of top designs to retrieve: \"))\ntop_k = 3\n\ntop_X, top_y = find_topk_from_model(\n    surrogate_model,\n    preprocessor,\n    search_space,\n    output_constraints=OUTPUT_CONSTRAINTS,\n    input_constraints=INPUT_CONSTRAINTS,\n    objective=OBJECTIVE,\n    n_iter=1000000,\n    top_k=top_k\n)\n\nif top_X is not None:\n    for i, idx in enumerate(top_X.index, 1):\n        print(f\"\\nTop {i} Predicted Feasible Configuration:\")\n        config = top_X.loc[idx]\n        metrics = top_y.loc[idx]\n\n        print(\"Configuration (xi):\")\n        config_copy = config.copy()\n        if 'branch_predictor' in config_copy.index:\n            config_copy['BP'] = f'\"{config_copy[\"branch_predictor\"]}\"'\n            config_copy = config_copy.drop('branch_predictor')\n\n        for k, v in config_copy.items():\n            if isinstance(v, float):\n                print(f\"{k}={v:.6f}\")\n            else:\n                print(f\"{k}={v}\")\n\n        print(\"\\nPredicted Metrics:\")\n        print(metrics.to_string())\nelse:\n    print(\"\\nNo feasible configurations found for the given constraints.\")\n\nprint(\"\\n--- End of Script ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:07:00.103736Z","iopub.execute_input":"2025-10-27T19:07:00.104014Z","iopub.status.idle":"2025-10-27T19:07:01.176922Z","shell.execute_reply.started":"2025-10-27T19:07:00.103990Z","shell.execute_reply":"2025-10-27T19:07:01.176069Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\n [Part 3] Inference / Optimization (Top-K Designs)\n==================================================\nRunning ML-powered random search for 1000000 iterations...\nFound 6900 *predicted* feasible configurations.\n(6900, 15) (6900, 14)\n\nTop 1 Predicted Feasible Configuration:\nConfiguration (xi):\ncpu_clock_GHz=1.036969\nl1i_kb=128\nl1d_kb=64\nl1_assoc=8\nl2_kb=256\nl2_assoc=2\nfetchWidth=11\ndecodeWidth=4\nissueWidth=4\ncommitWidth=10\nnumROBEntries=115\nnumIQEntries=91\nLQEntries=51\nSQEntries=51\nBP=\"TAGE_SC_L_64KB\"\n\nPredicted Metrics:\nArea                           95.346718\nPeak Power                     32.597397\nTotal Leakage                  16.941883\nPeak Dynamic                   14.184817\nSubthreshold Leakage           15.854826\nGate Leakage                    1.196789\nRuntime Dynamic                 5.487137\nipc                             1.001851\nbranch_misprediction_rate       0.054943\nicache_miss_rate                0.008823\ndcache_read_miss_rate           0.015719\ndcache_write_miss_rate          0.010199\npca                          1349.976807\ncpi                             0.998152\n\nTop 2 Predicted Feasible Configuration:\nConfiguration (xi):\ncpu_clock_GHz=1.040777\nl1i_kb=32\nl1d_kb=128\nl1_assoc=2\nl2_kb=256\nl2_assoc=4\nfetchWidth=9\ndecodeWidth=4\nissueWidth=4\ncommitWidth=12\nnumROBEntries=131\nnumIQEntries=105\nLQEntries=22\nSQEntries=32\nBP=\"TAGE\"\n\nPredicted Metrics:\nArea                           92.260155\nPeak Power                     34.209019\nTotal Leakage                  16.929893\nPeak Dynamic                   15.412192\nSubthreshold Leakage           15.843046\nGate Leakage                    1.193921\nRuntime Dynamic                 5.823072\nipc                             1.002270\nbranch_misprediction_rate       0.052311\nicache_miss_rate                0.009662\ndcache_read_miss_rate           0.011672\ndcache_write_miss_rate          0.010056\npca                          1418.710449\ncpi                             0.997735\n\nTop 3 Predicted Feasible Configuration:\nConfiguration (xi):\ncpu_clock_GHz=1.017859\nl1i_kb=128\nl1d_kb=128\nl1_assoc=4\nl2_kb=128\nl2_assoc=4\nfetchWidth=11\ndecodeWidth=5\nissueWidth=4\ncommitWidth=8\nnumROBEntries=34\nnumIQEntries=103\nLQEntries=53\nSQEntries=37\nBP=\"TAGE_SC_L_64KB\"\n\nPredicted Metrics:\nArea                           98.127029\nPeak Power                     33.797085\nTotal Leakage                  17.033464\nPeak Dynamic                   15.262534\nSubthreshold Leakage           15.948348\nGate Leakage                    1.197550\nRuntime Dynamic                 5.500666\nipc                             1.006145\nbranch_misprediction_rate       0.054379\nicache_miss_rate                0.008824\ndcache_read_miss_rate           0.011741\ndcache_write_miss_rate          0.010056\npca                          1488.520142\ncpi                             0.993893\n\n--- End of Script ---\n","output_type":"stream"}],"execution_count":9}]}